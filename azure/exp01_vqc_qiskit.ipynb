{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ‘‹ðŸŒ DGA Botnet detection - Qiskit version over Microsoft Q-Devices\n",
        "\n",
        "In this notebook, we'll review the application of Variational Quantum Classifiers for DGA-Botnet Detection"
      ],
      "metadata": {},
      "id": "b80086b5-ddee-4b7d-9a72-e62ddbc686c6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit a job to Microsoft Quantum Devices using Azure Quantum\n",
        "In this notebook we are using Qiskit. At the time of this writing, azure supports below machines:\n",
        "- ionq.qpu\n",
        "- ionq.qpu.aria-1\n",
        "- ionq.simulator\n",
        "- quantinuum.hqs-lt-s1\n",
        "- quantinuum.hqs-lt-s1-apival\n",
        "- quantinuum.hqs-lt-s2\n",
        "- quantinuum.hqs-lt-s2-apival\n",
        "- quantinuum.hqs-lt-s1-sim\n",
        "- quantinuum.hqs-lt-s2-sim\n",
        "- quantinuum.qpu.h1-1\n",
        "- quantinuum.sim.h1-1sc\n",
        "- quantinuum.qpu.h1-2\n",
        "- quantinuum.sim.h1-2sc\n",
        "- quantinuum.sim.h1-1e\n",
        "- quantinuum.sim.h1-2e\n",
        "- rigetti.sim.qvm\n",
        "- rigetti.qpu.aspen-11\n",
        "- rigetti.qpu.aspen-m-2\n",
        "- rigetti.qpu.aspen-m-3\n",
        "- microsoft.estimator\n",
        "\n",
        "\n",
        "Also, Qiskit provides below simulators:\n",
        "\n",
        "\n",
        "- AerSimulator('aer_simulator'),\n",
        "- AerSimulator('aer_simulator_statevector'),\n",
        "- AerSimulator('aer_simulator_density_matrix'),\n",
        "- AerSimulator('aer_simulator_stabilizer'),\n",
        "- AerSimulator('aer_simulator_matrix_product_state'),\n",
        "- AerSimulator('aer_simulator_extended_stabilizer'),\n",
        "- AerSimulator('aer_simulator_unitary'),\n",
        "- AerSimulator('aer_simulator_superop'),\n",
        "- QasmSimulator('qasm_simulator'),\n",
        "- StatevectorSimulator('statevector_simulator'),\n",
        "- UnitarySimulator('unitary_simulator'),\n",
        "- PulseSimulator('pulse_simulator')\n",
        "\n",
        "We select the backend for our experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "b348c385-c06b-4625-80e4-b7229993d299"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Connect to the Azure Quantum workspace\n",
        "\n",
        "To connect to the Azure Quantum service, construct an instance of the `AzureQuantumProvider`. Note that it's imported from `azure.quantum.qiskit`."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "acc246d3-61d1-47e1-aa57-1007e303dea5"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.quantum.qiskit import AzureQuantumProvider\n",
        "provider = AzureQuantumProvider (\n",
        "    resource_id = \"/subscriptions/2501e059-13d8-4207-85d6-ec58656e2fae/resourceGroups/AzureQuantum/providers/Microsoft.Quantum/Workspaces/Rigetti\",\n",
        "    location = \"eastus\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {},
      "id": "10605935-066d-4591-831b-4db4fd08a0c9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qiskit has different versions and classifiers like QSVM has been changed to QSVC , to have a stable run we make sure that we have the version that matches this experiment/"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "2ae7c21b-e2a6-4a6d-bddf-585843083a4a"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit==0.31.0\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "555ca4d0-d2b5-47ee-8696-daf44e6b63a2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what providers and targets are enabled in this workspace with the following command:\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "f7c8327f-959f-4e22-a0be-9bafee3bd06a"
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.visualization import plot_histogram\n",
        "from qiskit.tools.monitor import job_monitor\n",
        "\n",
        "print(\"This workspace's targets:\")\n",
        "for backend in provider.backends():\n",
        "    print(\"- \" + backend.name())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "This workspace's targets:\n- ionq.qpu\n- ionq.qpu.aria-1\n- ionq.simulator\n- quantinuum.hqs-lt-s1\n- quantinuum.hqs-lt-s1-apival\n- quantinuum.hqs-lt-s2\n- quantinuum.hqs-lt-s2-apival\n- quantinuum.hqs-lt-s1-sim\n- quantinuum.hqs-lt-s2-sim\n- quantinuum.qpu.h1-1\n- quantinuum.sim.h1-1sc\n- quantinuum.qpu.h1-2\n- quantinuum.sim.h1-2sc\n- quantinuum.sim.h1-1e\n- quantinuum.sim.h1-2e\n- rigetti.sim.qvm\n- rigetti.qpu.aspen-11\n- rigetti.qpu.aspen-m-2\n- rigetti.qpu.aspen-m-3\n- microsoft.estimator\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "d2bfe612-69d3-4a74-821a-29aec54e7aa7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Uploading data from a container that we made\n",
        "Next, we upload the dataset metioned at https://ieee-dataport.org/open-access/botnet-dga-dataset#files to a container inside Azure Storage. This is necessary for current version of Jupiter available of azure quantum. We may make random smaller sample size to test that our code is good enough when we change the backend. To have the dataset for project, we use below commands. the URLs are from Azure storage that we made earlier."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "7eca20a7-2aee-401b-93e8-f1eef5c2f5ac"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/BotnetDgaDataset.rst"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2022-12-27 02:31:33--  https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/BotnetDgaDataset.rst\r\nResolving aq5efd7d2644dd406cb3ec2d.blob.core.windows.net (aq5efd7d2644dd406cb3ec2d.blob.core.windows.net)... 52.239.169.4\r\nConnecting to aq5efd7d2644dd406cb3ec2d.blob.core.windows.net (aq5efd7d2644dd406cb3ec2d.blob.core.windows.net)|52.239.169.4|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 571 [application/octet-stream]\r\nSaving to: â€˜BotnetDgaDataset.rstâ€™\r\n\r\n\rBotnetDgaDataset.rs   0%[                    ]       0  --.-KB/s               \rBotnetDgaDataset.rs 100%[===================>]     571  --.-KB/s    in 0s      \r\n\r\n2022-12-27 02:31:33 (8.55 MB/s) - â€˜BotnetDgaDataset.rstâ€™ saved [571/571]\r\n\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "45b0ccb2-a64f-4b78-adb5-0a96e17499a8"
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/dgabotnet_main.csv\r\n",
        "!wget https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/BotnetDgaDataset_1000.csv\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2022-12-27 02:31:36--  https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/BotnetDgaDataset_1000.csv\nResolving aq5efd7d2644dd406cb3ec2d.blob.core.windows.net (aq5efd7d2644dd406cb3ec2d.blob.core.windows.net)... 52.239.169.4\nConnecting to aq5efd7d2644dd406cb3ec2d.blob.core.windows.net (aq5efd7d2644dd406cb3ec2d.blob.core.windows.net)|52.239.169.4|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75901 (74K) [text/csv]\nSaving to: â€˜BotnetDgaDataset_1000.csvâ€™\n\nBotnetDgaDataset_10 100%[===================>]  74.12K  --.-KB/s    in 0.1s    \n\n2022-12-27 02:31:37 (593 KB/s) - â€˜BotnetDgaDataset_1000.csvâ€™ saved [75901/75901]\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "892560a1-0647-4a5b-a187-647f22a039f3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned earlier, because the lack of file operation, we may use below code to be sure that our data is in the right location"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "c5a9b0fc-648f-447c-9e81-df77285a792d"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "files = os.listdir(os.curdir)\r\n",
        "for file in files:\r\n",
        "    print(file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": ".bash_logout\n.bashrc\n.profile\n.jupyter\nBotnetDgaDataset_1000.csv\nBotnetDgaDataset.rst\n.local\n.ipython\nazurequantumtoken.json\n.gitconfig\n.dotnet\n.nuget\n.templateengine\n.azure\n.packages\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "5232eef5-276e-456c-b60d-249a1427fc41"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case we need the list of Qiskit simulators"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0b04b25c-1549-4962-941e-aed3a17a5e7f"
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\r\n",
        "from qiskit import execute, Aer\r\n",
        "Aer.backends()\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "[AerSimulator('aer_simulator'),\n AerSimulator('aer_simulator_statevector'),\n AerSimulator('aer_simulator_density_matrix'),\n AerSimulator('aer_simulator_stabilizer'),\n AerSimulator('aer_simulator_matrix_product_state'),\n AerSimulator('aer_simulator_extended_stabilizer'),\n AerSimulator('aer_simulator_unitary'),\n AerSimulator('aer_simulator_superop'),\n QasmSimulator('qasm_simulator'),\n StatevectorSimulator('statevector_simulator'),\n UnitarySimulator('unitary_simulator'),\n PulseSimulator('pulse_simulator')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "4988455b-4ae3-49a4-86a9-d1f0632b65fd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Running the VQC\r\n",
        "The first version of this code is taken from DOI: 10.24433/CO.4005597.v2 accesible from: https://codeocean.com/capsule/3610673/tree/v2 \r\n",
        " \r\n",
        "The pseudocode is as below: \r\n",
        "1. Import necessary libraries including qiskit, numpy, pandas, matplotlib, and concurrent.futures.\r\n",
        "2. Define function to load data from a CSV file, including reading in the file, storing relevant information such as the number of samples and features, and returning the data, target, and target names as arrays.\r\n",
        "3. Define function to convert data and target into a dataframe with appropriate column names, and return the combined dataframe, data, and target.\r\n",
        "4. Define function to load botnet data, including reading in the file and returning data and target.\r\n",
        "5. Define main function to perform quantum-enhanced machine learning on botnet data, including options for standardizing, scaling, and binarizing the data.\r\n",
        "6. Split the data into training and test sets.\r\n",
        "7. Set up quantum circuit and choose optimization algorithm.\r\n",
        "8. Train model using quantum circuit and optimization algorithm.\r\n",
        "9. Test model on test set and calculate accuracy.\r\n",
        "10. Plot results as a histogram.\r\n",
        "11. Save results to a text file.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "937e4691-7a8c-4229-b038-427e608450a2"
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit\r\n",
        "from qiskit import QuantumCircuit\r\n",
        "from qiskit import Aer, transpile\r\n",
        "from qiskit.tools.visualization import plot_histogram, plot_state_city\r\n",
        "import qiskit.quantum_info as qi\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from qiskit import BasicAer\r\n",
        "from qiskit.aqua import QuantumInstance, aqua_globals\r\n",
        "from qiskit.aqua.algorithms import VQC\r\n",
        "\r\n",
        "from qiskit.aqua.components.optimizers import SPSA, ADAM, AQGD, CG, COBYLA, L_BFGS_B, GSLS, NELDER_MEAD, NFT, P_BFGS, POWELL, SLSQP, TNC\r\n",
        "from qiskit.aqua.components.feature_maps import RawFeatureVector\r\n",
        "from qiskit.circuit.library import TwoLocal, PauliFeatureMap, ZFeatureMap, ZZFeatureMap, NLocal, TwoLocal, RealAmplitudes, EfficientSU2, ExcitationPreserving\r\n",
        "from qiskit.aqua.utils import split_dataset_to_data_and_labels, map_label_to_class_name, get_feature_dimension\r\n",
        "import csv\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import datetime\r\n",
        "import concurrent.futures\r\n",
        "import time\r\n",
        "datafilename=\"BotnetDgaDataset_1000.csv\"\r\n",
        "resultname=\"result_BotnetDgaDataset_1000.txt\"\r\n",
        "cwd=os.getcwd()\r\n",
        "mycsv=cwd+\"/\"+datafilename\r\n",
        "\r\n",
        "\r\n",
        "def load_data(filepath):\r\n",
        "\r\n",
        "    with open(filepath) as csv_file:\r\n",
        "        data_file = csv.reader(csv_file)\r\n",
        "        temp = next(data_file)\r\n",
        "        n_samples = 1000\r\n",
        "        # int(temp[0])\r\n",
        "        n_features = 7\r\n",
        "        #int(temp[1])\r\n",
        "        target_names = np.array(temp[2:])\r\n",
        "        data = np.empty((n_samples, n_features))\r\n",
        "        target = np.empty((n_samples,), dtype=int)\r\n",
        "\r\n",
        "        for i, ir in enumerate(data_file):\r\n",
        "            data[i] = np.asarray(ir[:-1], dtype=np.float64)\r\n",
        "            target[i] = np.asarray(ir[-1], dtype=int)\r\n",
        "\r\n",
        "    return data, target, target_names\r\n",
        "\r\n",
        "load_data(mycsv)\r\n",
        "\r\n",
        "def _convert_data_dataframe(data, target,\r\n",
        "                            feature_names, target_names):\r\n",
        "    data_df = pd.DataFrame(data, columns=feature_names)\r\n",
        "    target_df = pd.DataFrame(target, columns=target_names)\r\n",
        "    combined_df = pd.concat([data_df, target_df], axis=1)\r\n",
        "    X = combined_df[feature_names]\r\n",
        "    y = combined_df[target_names]\r\n",
        "    if y.shape[1] == 1:\r\n",
        "        y = y.iloc[:, 0]\r\n",
        "    return combined_df, X, y\r\n",
        "\r\n",
        "\r\n",
        "def load_botnetdga(*, as_frame=False):\r\n",
        "\r\n",
        "    data, target, target_names = load_data(datafilename)\r\n",
        "\r\n",
        "    with open('BotnetDgaDataset.rst') as rst_file:\r\n",
        "        fdescr = rst_file.read()\r\n",
        "\r\n",
        "    feature_names = ['MinREBotnets',\r\n",
        "                     'CharLength',\r\n",
        "                     'TreeNewFeature',\r\n",
        "                     'nGramReputation_Alexa']\r\n",
        "\r\n",
        "    frame = None\r\n",
        "    target_columns = ['target', ]\r\n",
        "    if as_frame:\r\n",
        "        frame, data, target = _convert_data_dataframe(data,\r\n",
        "                                                      target,\r\n",
        "                                                      feature_names,\r\n",
        "                                                      target_columns)\r\n",
        "\r\n",
        "    return data, target\r\n",
        "\r\n",
        "\r\n",
        "def botnetdga(training_size, test_size, n,\r\n",
        "              standardize=False, pca=False, scale=False, plot_data=False,\r\n",
        "              binarize=False):\r\n",
        "    \r\n",
        "    class_labels = [r'benign', r'dga']\r\n",
        "\r\n",
        "    data, target = load_botnetdga()\r\n",
        "    sample_train, sample_test, label_train, label_test = \\\r\n",
        "        train_test_split(data, target, train_size=training_size, test_size=test_size, random_state=7)\r\n",
        "\r\n",
        "    \r\n",
        "    # Now we standardize for gaussian around 0 with unit variance\r\n",
        "    if standardize:\r\n",
        "        std_scale = StandardScaler().fit(sample_train)\r\n",
        "        sample_train = std_scale.transform(sample_train)\r\n",
        "        sample_test = std_scale.transform(sample_test)\r\n",
        "\r\n",
        "    \r\n",
        "    # Now reduce number of features to number of qubits\r\n",
        "    if pca:\r\n",
        "        pca = PCA(n_components=n).fit(sample_train)\r\n",
        "        sample_train = pca.transform(sample_train)\r\n",
        "        sample_test = pca.transform(sample_test)\r\n",
        "\r\n",
        "    \r\n",
        "    # Scale to the range (-1,+1)\r\n",
        "    if scale:\r\n",
        "        samples = np.append(sample_train, sample_test, axis=0)\r\n",
        "        minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\r\n",
        "        sample_train = minmax_scale.transform(sample_train)\r\n",
        "        sample_test = minmax_scale.transform(sample_test)\r\n",
        "\r\n",
        "    \r\n",
        "    if binarize:\r\n",
        "        med = np.median(np.append(sample_train, sample_test, axis=0), axis=0)\r\n",
        "\r\n",
        "        transformer = Binarizer(threshold=med)\r\n",
        "    \r\n",
        "        sample_train = transformer.transform(sample_train)\r\n",
        "        sample_test = transformer.transform(sample_test)\r\n",
        "\r\n",
        "    \r\n",
        "    # Pick training size number of samples from each distro\r\n",
        "    training_input = {key: (sample_train[label_train == k, :])[:training_size]\r\n",
        "                      for k, key in enumerate(class_labels)}\r\n",
        "    test_input = {key: (sample_test[label_test == k, :])[:test_size]\r\n",
        "                  for k, key in enumerate(class_labels)}\r\n",
        "\r\n",
        "    if plot_data:\r\n",
        "        LegitMinREBotnets = []\r\n",
        "        LegitCharLength = []\r\n",
        "        LegitTreeNewFeature = []\r\n",
        "        LegitnGramReputation_Alexa = []\r\n",
        "\r\n",
        "        DgaMinREBotnets = []\r\n",
        "        DgaCharLength = []\r\n",
        "        DgaTreeNewFeature = []\r\n",
        "        DganGramReputation_Alexa = []\r\n",
        "\r\n",
        "    \r\n",
        "        i = 0\r\n",
        "        while i < len(sample_train):\r\n",
        "            if label_train[i] == 0:\r\n",
        "                LegitMinREBotnets.append(sample_train[i][2])\r\n",
        "                LegitCharLength.append(sample_train[i][4])\r\n",
        "                LegitTreeNewFeature.append(sample_train[i][5])\r\n",
        "                LegitnGramReputation_Alexa.append(sample_train[i][6])\r\n",
        "            else:\r\n",
        "                DgaMinREBotnets.append(sample_train[i][2])\r\n",
        "                DgaCharLength.append(sample_train[i][4])\r\n",
        "                DgaTreeNewFeature.append(sample_train[i][5])\r\n",
        "                DganGramReputation_Alexa.append(sample_train[i][6])\r\n",
        "            i += 1\r\n",
        "        n_bins = None\r\n",
        "        class_labels = [r'benign', r'dga']\r\n",
        "        colors = ['blue', 'green']\r\n",
        "        x0 = [LegitMinREBotnets, DgaMinREBotnets]\r\n",
        "        x1 = [LegitCharLength, DgaCharLength]\r\n",
        "        x2 = [LegitTreeNewFeature, DgaTreeNewFeature]\r\n",
        "        x3 = [LegitnGramReputation_Alexa, DganGramReputation_Alexa]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\r\n",
        "\r\n",
        "\r\n",
        "        ax0.hist(x0, n_bins, density=True, histtype='bar', color=colors, label=class_labels)\r\n",
        "        ax0.legend(prop={'size': 10})\r\n",
        "        ax0.set_title('MinREBotnets')\r\n",
        "\r\n",
        "        ax1.hist(x1, n_bins, density=True, histtype='bar', color=colors, label=class_labels)\r\n",
        "        ax1.legend(prop={'size': 10})\r\n",
        "        ax1.set_title('CharLength')\r\n",
        "\r\n",
        "        ax2.hist(x2, n_bins, density=True, histtype='bar', color=colors, label=class_labels)\r\n",
        "        ax2.legend(prop={'size': 10})\r\n",
        "        ax2.set_title('TreeNewFeature')\r\n",
        "\r\n",
        "        ax3.hist(x3, n_bins, density=True, histtype='bar', color=colors, label=class_labels)\r\n",
        "        ax3.legend(prop={'size': 10})\r\n",
        "        ax3.set_title('nGramReputation_Alexa')\r\n",
        "\r\n",
        "        fig.tight_layout()\r\n",
        "        plt.show()\r\n",
        "\r\n",
        "    return sample_train, training_input, test_input, class_labels\r\n",
        "\r\n",
        "\r\n",
        "def runTheComputation(experimentID, optimizer, feature_map, var_form, training_input, test_input):\r\n",
        "    print(f'# Experiment  {experimentID}  = ')\r\n",
        "    \r\n",
        "    start = time.perf_counter()\r\n",
        "    #backend = provider.get_backend(\"ionq.simulator\")\r\n",
        "    #quantum_instance = QuantumInstance(backend)\r\n",
        "    vqc = VQC(optimizer,\r\n",
        "              feature_map,\r\n",
        "              var_form,\r\n",
        "              training_input,\r\n",
        "              test_input)\r\n",
        "\r\n",
        "    #backend = BasicAer.get_backend('statevector_simulator')\r\n",
        "    backend = Aer.get_backend('qasm_simulator')\r\n",
        "    \r\n",
        "\r\n",
        "    quantum_instance = QuantumInstance(backend)\r\n",
        "  \r\n",
        "    \r\n",
        "    \r\n",
        "    result = vqc.run(quantum_instance)\r\n",
        "\r\n",
        "\r\n",
        "    finish = time.perf_counter()\r\n",
        "\r\n",
        "    print('\\n' + str(experimentID) + ')  Accuracy =  ' + str(result['testing_accuracy'])  + '  ; nQubits =  ' + str(feature_map.num_qubits) )\r\n",
        "    \r\n",
        "    f = open(resultname, \"a\")\r\n",
        "    f.write('\\n' + str(experimentID) + ')  Accuracy =  ' + str(result['testing_accuracy'])  + '  ; nQubits =  ' + str(feature_map.num_qubits) )\r\n",
        "    f.flush()\r\n",
        "    f.close()\r\n",
        "    \r\n",
        "    return experimentID, result['testing_accuracy'], feature_map.num_qubits, round(finish - start, 2)\r\n",
        "\r\n",
        "\r\n",
        "def main():\r\n",
        "    \r\n",
        "\r\n",
        "    start = time.perf_counter()\r\n",
        "    print(mycsv)\r\n",
        "    # BotnetDGA data set\r\n",
        "    plot_data = False\r\n",
        "    training_size = 700\r\n",
        "    #1352500\r\n",
        "    test_size = 300\r\n",
        "    #450833\r\n",
        "    feature_dim = 7\r\n",
        "    standardize = False\r\n",
        "    pca = False\r\n",
        "    scale = False\r\n",
        "    binarize = False\r\n",
        "    \r\n",
        "    f = open(resultname, \"a\")\r\n",
        "    f.write(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S_\") + \"   training_size = \" + str(training_size) + \"  test_size = \" + str(test_size) + \"  feature_dim = \" + str(\r\n",
        "        feature_dim) + \"\\n\\n\")\r\n",
        "    f.flush()\r\n",
        "    f.close()\r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "    sample_train, training_input, test_input, class_labels = botnetdga(training_size=training_size,\r\n",
        "                                                                       test_size=test_size,\r\n",
        "                                                                       n=feature_dim,\r\n",
        "                                                                       standardize=standardize,\r\n",
        "                                                                       pca=pca,\r\n",
        "                                                                       scale=scale,\r\n",
        "                                                                       plot_data=plot_data,\r\n",
        "                                                                       binarize=binarize)\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    optimizer1 = SLSQP()\r\n",
        "    \r\n",
        "    nFeature = get_feature_dimension(training_input)\r\n",
        "\r\n",
        "    feature_map1 = RawFeatureVector(nFeature)\r\n",
        "    \r\n",
        "    var_form11 = TwoLocal(feature_map1.num_qubits, ['ry', 'rz'], 'cz')\r\n",
        "    \r\n",
        "    with concurrent.futures.ProcessPoolExecutor() as executor:\r\n",
        "        executor.submit(runTheComputation, 1, optimizer1, feature_map1, var_form11, training_input, test_input)\r\n",
        "        print(runTheComputation)\r\n",
        "    finish = time.perf_counter()\r\n",
        "\r\n",
        "    print(f'ALL Finished in {round( (finish-start)/3600, 2)} hour(s)')\r\n",
        "    f = open(resultname, \"a\")\r\n",
        "    f.write(f'ALL Finished in {round( (finish-start)/3600, 2)} hour(s)')\r\n",
        "    f.write(f'ALL Finished in {round( (finish-start), 2)} second(s)')\r\n",
        "    f.flush()\r\n",
        "    f.close()\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    main()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/home/jovyan/BotnetDgaDataset_1000.csv\n# Experiment  1  = \n<function runTheComputation at 0x7fe8cb4683a0>\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0c9e3569-f38f-4000-abe4-e0cca8be37fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the results inside the textfile"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "63210305-79a7-4302-9af5-008d93aef1d9"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "os.chdir('/home/jovyan/')\r\n",
        "path=os.getcwd()\r\n",
        "print(path)\r\n",
        "print(resultname)\r\n",
        "files = os.listdir(os.curdir)\r\n",
        "#for file in files:\r\n",
        "#    print(file)\r\n",
        "with open(resultname) as f:\r\n",
        "    s = f.read()\r\n",
        "print(s)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "eb0f52e2-ba96-4b37-b8a1-d0f812893cdd"
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit\r\n",
        "print(qiskit.__version__)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "6527501a-75a9-4ece-b36c-85c8f6a17826"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit --upgrade\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a85566f9-51d3-409f-b253-848f81b909fd"
    },
    {
      "cell_type": "code",
      "source": [
        "import qiskit\r\n",
        "print(qiskit.__version__)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "288a6b9c-b46b-4e7b-a716-b64a2163f8ec"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureQuantum": {
          "sourceType": "SampleGallery",
          "sourceLink": "https://raw.githubusercontent.com/microsoft/Quantum/f7d76cc28219b577404437b993a8fdfdc0dad33e/samples/azure-quantum/hello-world/HW-ionq-qiskit.ipynb"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}